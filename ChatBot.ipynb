{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYRGsELGuE2x",
    "outputId": "83026c3e-4c84-4e36-d399-24dd47e7f449"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/77.0 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━\u001B[0m \u001B[32m71.7/77.0 kB\u001B[0m \u001B[31m2.2 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m77.0/77.0 kB\u001B[0m \u001B[31m1.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import openai"
   ],
   "metadata": {
    "id": "iJImxwAYuxkr"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "openai.api_key = 'sk---'"
   ],
   "metadata": {
    "id": "LFtceiKOu4sc"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Method 1 - using OpenAI Python Package**"
   ],
   "metadata": {
    "id": "tiEMJ_u1w7Np"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"you are a kind helpful assistant.\"},\n",
    "]"
   ],
   "metadata": {
    "id": "HVg4rZE_xHwK"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from openai.api_resources import model\n",
    "while True:\n",
    "  message = input(\"User: \")\n",
    "  if message:\n",
    "    messages.append(\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    )\n",
    "    chat = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", messages=messages\n",
    "    )\n",
    "    reply = chat.choices[0].message.content\n",
    "    print(f\"ChatGPT: {reply}\")\n",
    "    messages.append({\"role\": \"assistant\", \"content\": reply})"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 792
    },
    "id": "NRoa6GJFzSZb",
    "outputId": "d7823fc8-010a-4d7d-d213-33d0b3dfa50f"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "User: what's your name?\n",
      "ChatGPT: I am an AI language model created by OpenAI, and I don't have a personal name. You can simply refer to me as \"Assistant.\" How can I assist you today?\n",
      "User: You know my name?\n",
      "ChatGPT: No, as an AI language model, I don't have access to personal data unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality. My primary function is to provide information and answer questions to the best of my knowledge and abilities. If you have any concerns about privacy or data security, please let me know, and I will do my best to address them.\n",
      "User: My name is Nikita.\n",
      "ChatGPT: Hello, Nikita! How can I assist you today?\n",
      "User: Do you know what a ML Engineer do?\n",
      "ChatGPT: Yes, I can provide some information about what a Machine Learning (ML) Engineer does. ML Engineers are professionals who specialize in developing and deploying machine learning models and systems. Their role involves various tasks such as:\n",
      "\n",
      "1. Data preprocessing: ML Engineers collect, clean, and preprocess data to make it suitable for training machine learning models.\n",
      "\n",
      "2. Model development: They design and build machine learning models using algorithms and techniques such as deep learning, decision trees, or support vector machines.\n",
      "\n",
      "3. Model training: ML Engineers train machine learning models using large datasets, tuning hyperparameters, and optimizing performance.\n",
      "\n",
      "4. Evaluation and testing: They evaluate the performance of machine learning models and conduct rigorous testing to ensure their accuracy and functionality.\n",
      "\n",
      "5. Deployment: ML Engineers deploy machine learning models into production environments, integrating them into larger software systems or platforms.\n",
      "\n",
      "6. Monitoring and maintenance: They monitor the performance of deployed models, troubleshoot issues, and continuously improve and update the models as needed.\n",
      "\n",
      "Additionally, ML Engineers often collaborate with data scientists, software engineers, and domain experts to understand business requirements and develop effective machine learning solutions.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-10-a8d068fa6e31>\u001B[0m in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mopenai\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapi_resources\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m   \u001B[0mmessage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"User: \"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0mmessage\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     messages.append(\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001B[0m in \u001B[0;36mraw_input\u001B[0;34m(self, prompt)\u001B[0m\n\u001B[1;32m    849\u001B[0m                 \u001B[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    850\u001B[0m             )\n\u001B[0;32m--> 851\u001B[0;31m         return self._input_request(str(prompt),\n\u001B[0m\u001B[1;32m    852\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_parent_ident\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    853\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_parent_header\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001B[0m in \u001B[0;36m_input_request\u001B[0;34m(self, prompt, ident, parent, password)\u001B[0m\n\u001B[1;32m    893\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyboardInterrupt\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    894\u001B[0m                 \u001B[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 895\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mKeyboardInterrupt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Interrupted by user\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    896\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    897\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwarning\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Invalid Message:\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexc_info\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: Interrupted by user"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Method 2 - Using API Endpoint**"
   ],
   "metadata": {
    "id": "8YRcJaUb6xvI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "payload = {\n",
    "\"model\": \"gpt-3.5-turbo\",\n",
    "\"messages\": [{\"role\": \"user\", \"content\": f\"Which is the first programming language in the world?\"}],\n",
    "\"temperature\" : 1.0,\n",
    "\"top_p\":1.0,\n",
    "\"n\" : 1,\n",
    "\"stream\": False,\n",
    "\"presence_penalty\":0,\n",
    "\"frequency_penalty\":0,\n",
    "}\n",
    "\n",
    "headers = {\n",
    "\"Content-Type\": \"application/json\",\n",
    "\"Authorization\": f\"Bearer {openai.api_key}\"\n",
    "}\n",
    "\n",
    "response = requests.post(URL, headers=headers, json=payload, stream=False)"
   ],
   "metadata": {
    "id": "ZhwngpDy7LQ9"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "response.content"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xu_w99cT7sI9",
    "outputId": "5afe6308-250e-4795-a173-e69a22252f8c"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "b'{\\n  \"id\": \"chatcmpl-85XDFARMx5bTR0lCIgGcbcEfv4U0t\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 1696330001,\\n  \"model\": \"gpt-3.5-turbo-0613\",\\n  \"choices\": [\\n    {\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": \"The first programming language in the world is considered to be Fortran (Formula Translation), which was developed by a team led by John W. Backus at IBM in the 1950s.\"\\n      },\\n      \"finish_reason\": \"stop\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 17,\\n    \"completion_tokens\": 39,\\n    \"total_tokens\": 56\\n  }\\n}\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  }
 ]
}
